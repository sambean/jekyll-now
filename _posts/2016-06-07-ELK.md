---
layout: post
title: 日志实时统计系统实现思路
---

   使用ELK搭建日志收集系统这个搭建的过程我就不赘述了,主要介绍一下数据统计的业务实现。

   刚搭建完elk的时候发现日志量好大啊,还有点小兴奋,结果一看数据吓一跳，70%的数据都是各种爬虫的爬取请求,真正的用户访问量才有30%,肯定不能让爬虫数据影响到业务数据,所以第一步就是要过滤掉爬虫。

   目前站点也接入了cnzz  pwiki这些第三方统计,但是这些工具更多是对一个网站数据的概览,而如果想要查询某一个具体的页面的pv uv referrer的趋势就很难去实现,并且对于站点的运营人员来说,使用cnzz pwiki也不算那么熟练,所以需要自建一个日志统计系统来满足这些业务需求.

   假设运营刚刚上了一个活动页,并且在不同的渠道进行了投放,想要实时去查看投放效果,那么怎么去实现这个业务需求呢?

   首先,我们会将所有的原始请求存储到DB里(mongodb,hdfs等等都是可选的),然后用hive或其他的一些工具进行离线计算后统计，这样做的缺点是实时性不高,想要实时性可以使用storm进行处理,这个topology的spout从redis的list中pop数据(因为elk一般会选择redis做日志传输中间件,当然也可以用kafka等等)，需要三个bolt:
   <ul>
   		<li>filterBolt: 这个bolt的作用是判断当前request是否需要被统计,因为并不是所有的request都是需要被统计的</li>
   		<li>pvBolt:统计当前request的pv</li>
   		<li>uvBolt:统计当前request的uv</li>
   		<li>referrerBolt:统计当前request的referrer</li>
   </ul>

使用redis进行计数 ,每个需要统计的页面会分配一个key,那么redis的key规则就是

key_type_date

例如: 统计key为activity1的页面的某一天的PV               activity1_pv_20160501
     统计key为activity1的页面的某一个小时的referrer:    activity1_referrer_20160501
     统计key为activity1的页面的某一个月的UV:    activity1_uv_201605

目前统计了 小时,天,周,月个维度的数据

对于pv就是计数,直接incrby即可
对于uv/referrer，则使用zset,因为uv需要去除,referrer的话需要记录具体的referrer值

最后需要一个定时任务将redis里的数据写到mysql里，提供给业务系统查询



 